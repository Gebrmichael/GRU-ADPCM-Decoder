{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32252201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa99457",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3696/1194450740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                      \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tanh\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                      \u001b[0mrecurrent_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                      input_shape=(X.shape[1], X.shape[2])))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# Add a dropout layer (penalizing more complex models) -- prevents overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# =================build GRU Architectur========================\n",
    "# Let's build the GRU\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add a GRU layer with 3 units.\n",
    "model.add(layers.GRU(3,\n",
    "                     activation = \"tanh\",\n",
    "                     recurrent_activation = \"sigmoid\",\n",
    "                     input_shape=(X.shape[1], X.shape[2])))\n",
    "# Add a dropout layer (penalizing more complex models) -- prevents overfitting\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "# Add a Dense layer with 1 units (Since we are doing a regression task.\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Evaluating loss function of MSE using the adam optimizer.\n",
    "model.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "\n",
    "# Print out architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the trained model\n",
    "# https://www.youtube.com/watch?v=vJWbSTJYXGM&t=236s \n",
    "model.save('ADPCM_GRU_speech_coding_trained_model_Adam_epoch_50_length_of_step_15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68d3b3",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b069e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Author: Gebremichael\n",
    "# @File: dialogic_ADPCM.py \n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "# table of index\n",
    "IndexTable = [-1, -1, -1, -1, 2, 4, 6, 8, -1, -1, -1, -1, 2, 4, 6, 8]\n",
    "\n",
    "# table of  quantizer step size\n",
    "StepSizeTable = [7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 21, 23, 25, 28, 31, 34, 37, 41, 45, 50, 55, 60, 66, 73, 80, 88, 97, 107, 118, 130, 143, 157, 173, 190, 209, 230, 253, 279, 307, 337, 371, 408, 449, 494, 544, 598, 658, 724, 796, 876, 963, 1060, 1166, 1282, 1411, 1552, 1707, 1878, 2066, 2272, 2499, 2749, 3024, 3327, 3660, 4026, 4428, 4871, 5358, 5894, 6484, 7132, 7845, 8630, 9493, 10442, 11487, 12635, 13899, 15289, 16818, 18500, 20350, 22385, 24623, 27086, 29794, 32767]\n",
    "\n",
    "# ADPCM_Encode.\n",
    "# sample: a 16-bit PCM sample\n",
    "# retval : a 4-bit ADPCM sample\n",
    "predsample = 0\n",
    "index = 0\n",
    "\n",
    "# # ======================================================================================\n",
    "# Encoding from PCM to ADPCM (16-bit PCM sample to 4-bit ADPCM  sample word length)\n",
    "def ADPCM_Encode(sample):\n",
    "    global index\n",
    "    global predsample\n",
    "    global diffq\n",
    "    global ore_diff\n",
    "    global error_signal\n",
    "    \n",
    "    code = 0\n",
    "    \n",
    "    step_size = StepSizeTable[index]\n",
    "\n",
    "    # compute diff and record sign and absolut value\n",
    "          \n",
    "    diff = sample - predsample\n",
    "    ore_diff=diff\n",
    "    #print('diff sample:' ,ore_diff)\n",
    "    if diff < 0:\n",
    "        code = 8\n",
    "        diff = -diff\n",
    "\n",
    "    # quantize the diff into ADPCM code\n",
    "    # inverse quantize the code into a predicted diff\n",
    "    tmpstep = step_size\n",
    "    diffq = step_size >> 3\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x04\n",
    "        diff -= tmpstep\n",
    "        diffq = diffq + step_size\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x02\n",
    "        diff = diff - tmpstep\n",
    "        diffq = diffq + (step_size >> 1)\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x01\n",
    "        diffq = diffq + (step_size >> 2)\n",
    "    \n",
    "    # fixed predictor to get new predicted sample\n",
    "    if code & 8:\n",
    "        predsample = predsample - diffq\n",
    "    else:\n",
    "        predsample = predsample + diffq\n",
    "         \n",
    "    # check for overflow\n",
    "    if predsample > 32767:\n",
    "        predsample = 32767\n",
    "    elif predsample < -32768:\n",
    "        predsample = -32768\n",
    "\n",
    "    # find new stepsize index\n",
    "    index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if index < 0:\n",
    "        index = 0\n",
    "\n",
    "    if index > 88:\n",
    "        index = 88\n",
    "    error_signal = sample - predsample\n",
    "    \n",
    "    # return new ADPCM code code & 0x0f == code\n",
    "    return code & 0x0f\n",
    "\n",
    "\n",
    "# ADPCM_Decode.\n",
    "# code: a byte containing a 4-bit ADPCM sample.\n",
    "# retval: 16-bit ADPCM sample\n",
    "de_index = 0\n",
    "de_predsample = 0\n",
    "\n",
    "# ======================================================================================\n",
    "# Decoding from ADPCM to PCM  ( a 4-bit ADPCM sample to 16-bit PCM sample word length)\n",
    "def ADPCM_Decode(code):\n",
    "    global de_index\n",
    "    global de_predsample\n",
    "\n",
    "    step_size = StepSizeTable[de_index]\n",
    "\n",
    "    # inverse code into diff    \n",
    "    diffq = step_size >> 3  # == step/8\n",
    "    if code & 4:\n",
    "        diffq += step_size\n",
    "\n",
    "    if code & 2:\n",
    "        diffq += step_size >> 1\n",
    "\n",
    "    if code & 1:\n",
    "        diffq += step_size >> 2\n",
    "\n",
    "       \n",
    "    # add diff to predicted sample\n",
    "    if code & 8:\n",
    "        diffq = -diffq\n",
    "\n",
    "    de_predsample += diffq\n",
    "\n",
    "    # check for overflow  clip the values to +/- 2^11 (supposed to be 16 bits)\n",
    "    if de_predsample > 32767:\n",
    "        de_predsample = 32767\n",
    "    elif de_predsample < -32768:\n",
    "        de_predsample = -32768\n",
    "\n",
    "    # find new quantizer step size\n",
    "    de_index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if de_index < 0:\n",
    "        de_index = 0\n",
    "\n",
    "    if de_index > 88:\n",
    "        de_index = 88\n",
    "\n",
    "    # save predict sample and de_index for next iteration\n",
    "    # return new decoded sample\n",
    "    # The original algorithm turned out to be 12bit, need to convert to 16bit\n",
    "    return de_predsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22390b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%pmatplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "# Plotting package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# .................scipy wave based data..............\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "audio_file = 'dataset/Test_dataset_all_8_speaker_merged_MS_and_FS.wav'\n",
    "\n",
    "fs, data = wavfile.read(audio_file)\n",
    "wavdata=data[::]\n",
    "\n",
    "\n",
    "org_samp=[]\n",
    "pre_samp=[]\n",
    "oreginal_diff=[]\n",
    "adpcm_code = []\n",
    "q_diff=[]\n",
    "err_signal=[]\n",
    "\n",
    "for i in range(len(wavdata)):\n",
    "    ADPCM_sample = ADPCM_Encode(wavdata[i])   \n",
    "    pred_sample = ADPCM_Decode(ADPCM_sample)\n",
    "    #print(\"Sample:\", wavdata[i])\n",
    "    #print(\"ADPCM code:\", sample)\n",
    "    #print('................................')\n",
    "    \n",
    "    org_samp.append(wavdata[i])\n",
    "    pre_samp.append(pred_sample)\n",
    "    oreginal_diff.append(ore_diff)\n",
    "    q_diff.append(diffq)\n",
    "    err_signal.append(error_signal)\n",
    "    \n",
    "org_samp=np.array(org_samp)           #oreginal signal samples\n",
    "pre_samp=np.array(pre_samp)           #predicted sample \n",
    "\n",
    "oreginal_diff=np.array(oreginal_diff) #the oreginal and predicted sample difference\n",
    "adpcm_code = np.array(adpcm_code)     #the ADPCM code the is transmited to decoder \n",
    "q_diff = np.array(q_diff)             #the quantized difference/inverse of quantization difference\n",
    "e_signal=np.array(err_signal)         #the error of the prediction (residual signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4f3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data Between 0 and 1\n",
    "y = org_samp\n",
    "ypn = pre_samp\n",
    "\n",
    "org_samp = np.array(y)\n",
    "# goal : range [0, 1]\n",
    "org_samp = (org_samp - min(org_samp)) / ( max(org_samp) - min(org_samp) )\n",
    "\n",
    "pre_samp = np.array(ypn)\n",
    "pre_samp = (pre_samp - min(pre_samp)) / ( max(pre_samp) - min(pre_samp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549d79d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 3)                 54        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# to load or run the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model=load_model('ADPCM_GRU_speech_coding_trained_model_Adam_epoch_50_length_of_step_10.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6493ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: Length is  10 :  [[[0.46758651]\n",
      "  [0.46764126]\n",
      "  [0.46758651]\n",
      "  [0.46753176]\n",
      "  [0.467477  ]\n",
      "  [0.46753176]\n",
      "  [0.46758651]\n",
      "  [0.46753176]\n",
      "  [0.46753176]\n",
      "  [0.46753176]]]\n",
      "Testing Data: Length is  1 :  [[0.4691338]]\n",
      "Dimensions of X: (2187064, 10, 1)\n",
      "Dimensions of Y: (2187064, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===============Step 0: Data Preparation==============\n",
    "# Need the data to be in the form [sample, time steps, features (dimension of each element)]\n",
    "samples = 10 # Number of samples (in past)\n",
    "steps = 1 # Number of steps (in future)\n",
    "X = [] # X array\n",
    "Y = [] # Y array\n",
    "\n",
    "for i in range(wavdata.shape[0] - samples): \n",
    "    X.append(pre_samp[i:i+samples]) # Independent Samples\n",
    "    Y.append(org_samp[i+samples-1]) # Dependent Samples\n",
    "X = np.array(X)\n",
    "X = np.expand_dims(X, axis=2)\n",
    "Y = np.array(Y)\n",
    "Y = np.expand_dims(Y, axis=1)\n",
    "\n",
    "print('Training Data: Length is ',len(X[0:1][0]),': ', X[0:1])\n",
    "print('Testing Data: Length is ', len(Y[0:1]),': ', Y[0:1])\n",
    "\n",
    "print('Dimensions of X:', X.shape) \n",
    "print('Dimensions of Y:', Y.shape)\n",
    "\n",
    "# threshold = round(0.9 * X.shape[0])\n",
    "# print('Threshold is', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004ea2e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Length: (2187064, 10, 1) (2187064, 1)\n",
      "68346/68346 [==============================] - 146s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GM\\AppData\\Local\\Temp/ipykernel_9696/3699182037.py:24: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(\"Fixed predictor of IMA-ADPCM signal.png\", dpi=300, bbox_inches='tight')\n"
     ]
    }
   ],
   "source": [
    "# =========================preparing testing set========================\n",
    "testX, testY =  X[:], Y[:]\n",
    "print('Testing Length:',testX.shape, testY.shape)\n",
    "\n",
    "\n",
    "#====================This is a one step forecast (based on that we have constructed the model)====================\n",
    "plt.figure(figsize=(12, 4))\n",
    "y_pred = loaded_model.predict(testX)\n",
    "\n",
    "# Oreginal speech signal data\n",
    "plt.title('The Original PCM and predicted Speech Signal') \n",
    "plt.plot(testY, 'b', label='Original Signal sample')\n",
    "\n",
    "# Predicted speech signal data\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Amplitude (Quantization level)')\n",
    "plt.plot(y_pred, 'g', label='predicted Speech Signal')\n",
    "plt.legend(loc='upper center')\n",
    "\n",
    "error_signal = testY - y_pred\n",
    "plt.plot(error_signal, 'r', label = 'error_signal')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Fixed predictor of IMA-ADPCM signal.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe562093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To zoom and view the actual and predicted signal difference plot in between 3000 to 3050 the sample 50 samples\n",
    "plt.figure(figsize=(12, 4))\n",
    "# Oreginal speech signal data\n",
    "plt.title('The Original PCM and predicted Speech Signal it was randomly taken from 3000th to 3050th') \n",
    "plt.plot(testY[1300000:1300100], 'b', label='Original Signal sample')\n",
    "\n",
    "\n",
    "# Predicted speech signal data\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Amplitude (Quantization level)')\n",
    "plt.plot(y_pred[1300000:1300100], 'g', label='predict Signal sample')\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "\n",
    "plt.savefig(\"zoomed Fixed predictor with IMA-ADPCM 1300,000th to 1300,100th signal1.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================error_signal==========================\n",
    "plt.figure(figsize=(12, 4))\n",
    "error_signal = testY - y_pred\n",
    "#print(\"error_signal:\",error_signal)\n",
    "\n",
    "plt.plot(error_signal, label = 'error_signal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual and predicted signal plot \n",
    "plt.figure(figsize=(12, 4))\n",
    "# Oreginal speech signal data\n",
    "plt.title('The sample of male single sentence PCM speech signals') \n",
    "plt.plot(testY, 'b', label='Original Signal sample')\n",
    "\n",
    "# Predicted speech signal data\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Amplitude (Normalized Quantization level)')\n",
    "plt.plot(y_pred, 'g', label='predict Signal sample')\n",
    "plt.plot(error_signal, 'r', label='Error signal(difference of Actual and predicted)')\n",
    "plt.legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61785cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GRU_err = y_pred - testY\n",
    "GRU_err = testY[:] - y_pred[:] \n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(GRU_err, label = 'error_signal')\n",
    "plt.legend()\n",
    "\n",
    "dnn_mse = 10*np.log10(np.mean(pow(np.abs(GRU_err[:]),2)))\n",
    "dnn_sigpow = 10*np.log10(np.mean(pow(np.abs(testY),2)))\n",
    "\n",
    "#print(dnn_mse, dnn_sigpow, lms_mse, lms_sigpow)\n",
    "print(\"GRU predictor SNR:\", dnn_sigpow - dnn_mse, \"dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4a781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
