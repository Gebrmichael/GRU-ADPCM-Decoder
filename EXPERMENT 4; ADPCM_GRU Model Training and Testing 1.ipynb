{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504c8cff",
   "metadata": {},
   "source": [
    "### ==== Encoding and Decoding the speech samples ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336b8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Author: Gebremichael\n",
    "# @File: dialogic_ADPCM.py \n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "# table of index\n",
    "IndexTable = [-1, -1, -1, -1, 2, 4, 6, 8, -1, -1, -1, -1, 2, 4, 6, 8]\n",
    "\n",
    "# table of  quantizer step size\n",
    "StepSizeTable = [7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 21, 23, 25, 28, 31, 34, 37, 41, 45, 50, 55, 60, 66, 73, 80, 88, 97, 107, 118, 130, 143, 157, 173, 190, 209, 230, 253, 279, 307, 337, 371, 408, 449, 494, 544, 598, 658, 724, 796, 876, 963, 1060, 1166, 1282, 1411, 1552, 1707, 1878, 2066, 2272, 2499, 2749, 3024, 3327, 3660, 4026, 4428, 4871, 5358, 5894, 6484, 7132, 7845, 8630, 9493, 10442, 11487, 12635, 13899, 15289, 16818, 18500, 20350, 22385, 24623, 27086, 29794, 32767]\n",
    "\n",
    "# ADPCM_Encode.\n",
    "# sample: a 16-bit PCM sample\n",
    "# retval : a 4-bit ADPCM sample\n",
    "predsample = 0\n",
    "index = 0\n",
    "\n",
    "# # ======================================================================================\n",
    "# Encoding from PCM to ADPCM (16-bit PCM sample to 4-bit ADPCM  sample word length)\n",
    "def ADPCM_Encode(sample):\n",
    "    global index\n",
    "    global predsample\n",
    "    global diffq\n",
    "    global ore_diff\n",
    "    global error_signal\n",
    "    \n",
    "    code = 0\n",
    "    \n",
    "    step_size = StepSizeTable[index]\n",
    "\n",
    "    # compute diff and record sign and absolut value\n",
    "          \n",
    "    diff = sample - predsample\n",
    "    ore_diff=diff\n",
    "    #print('diff sample:' ,ore_diff)\n",
    "    if diff < 0:\n",
    "        code = 8\n",
    "        diff = -diff\n",
    "\n",
    "    # quantize the diff into ADPCM code\n",
    "    # inverse quantize the code into a predicted diff\n",
    "    tmpstep = step_size\n",
    "    diffq = step_size >> 3\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x04\n",
    "        diff -= tmpstep\n",
    "        diffq = diffq + step_size\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x02\n",
    "        diff = diff - tmpstep\n",
    "        diffq = diffq + (step_size >> 1)\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x01\n",
    "        diffq = diffq + (step_size >> 2)\n",
    "    \n",
    "    # fixed predictor to get new predicted sample\n",
    "    if code & 8:\n",
    "        predsample = predsample - diffq\n",
    "    else:\n",
    "        predsample = predsample + diffq\n",
    "         \n",
    "    # check for overflow\n",
    "    if predsample > 32767:\n",
    "        predsample = 32767\n",
    "    elif predsample < -32768:\n",
    "        predsample = -32768\n",
    "\n",
    "    # find new stepsize index\n",
    "    index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if index < 0:\n",
    "        index = 0\n",
    "\n",
    "    if index > 88:\n",
    "        index = 88\n",
    "    error_signal = sample - predsample\n",
    "    \n",
    "    # return new ADPCM code code & 0x0f == code\n",
    "    return code & 0x0f\n",
    "\n",
    "\n",
    "# ADPCM_Decode.\n",
    "# code: a byte containing a 4-bit ADPCM sample.\n",
    "# retval: 16-bit ADPCM sample\n",
    "de_index = 0\n",
    "de_predsample = 0\n",
    "\n",
    "# ======================================================================================\n",
    "# Decoding from ADPCM to PCM  ( a 4-bit ADPCM sample to 16-bit PCM sample word length)\n",
    "def ADPCM_Decode(code):\n",
    "    global de_index\n",
    "    global de_predsample\n",
    "\n",
    "    step_size = StepSizeTable[de_index]\n",
    "\n",
    "    # inverse code into diff    \n",
    "    diffq = step_size >> 3  # == step/8\n",
    "    if code & 4:\n",
    "        diffq += step_size\n",
    "\n",
    "    if code & 2:\n",
    "        diffq += step_size >> 1\n",
    "\n",
    "    if code & 1:\n",
    "        diffq += step_size >> 2\n",
    "\n",
    "       \n",
    "    # add diff to predicted sample\n",
    "    if code & 8:\n",
    "        diffq = -diffq\n",
    "\n",
    "    de_predsample += diffq\n",
    "\n",
    "    # check for overflow  clip the values to +/- 2^11 (supposed to be 16 bits)\n",
    "    if de_predsample > 32767:\n",
    "        de_predsample = 32767\n",
    "    elif de_predsample < -32768:\n",
    "        de_predsample = -32768\n",
    "\n",
    "    # find new quantizer step size\n",
    "    de_index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if de_index < 0:\n",
    "        de_index = 0\n",
    "\n",
    "    if de_index > 88:\n",
    "        de_index = 88\n",
    "\n",
    "    # save predict sample and de_index for next iteration\n",
    "    # return new decoded sample\n",
    "    # The original algorithm turned out to be 12bit, need to convert to 16bit\n",
    "    return de_predsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d593c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%pmatplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "# Plotting package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============Different Data loading==============\n",
    "# ...............scipy wave based data..............\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "audio_file = 'audio_data/Test_dataset_All_4_speakers_merged_MS_and_FS.wav'\n",
    "fs, data = wavfile.read(audio_file)\n",
    "wavdata=data[::]\n",
    "\n",
    "# .................librosa based data..............\n",
    "#audio, fs = librosa.load(audio_file, sr = 8000)\n",
    "#wavdata=audio[:]\n",
    "\n",
    "org_samp=[]\n",
    "pre_samp=[]\n",
    "oreginal_diff=[]\n",
    "adpcm_code = []\n",
    "q_diff=[]\n",
    "err_signal=[]\n",
    "\n",
    "for i in range(len(wavdata)):\n",
    "    ADPCM_sample = ADPCM_Encode(wavdata[i])   \n",
    "    pred_sample = ADPCM_Decode(ADPCM_sample)\n",
    "    #print(\"Sample:\", wavdata[i])\n",
    "    #print(\"ADPCM code:\", sample)\n",
    "    #print('................................')\n",
    "    \n",
    "    org_samp.append(wavdata[i])\n",
    "    pre_samp.append(pred_sample)\n",
    "    oreginal_diff.append(ore_diff)\n",
    "    q_diff.append(diffq)\n",
    "    err_signal.append(error_signal)\n",
    "    \n",
    "org_samp=np.array(org_samp)           #oreginal signal samples\n",
    "pre_samp=np.array(pre_samp)           #predicted sample \n",
    "\n",
    "oreginal_diff=np.array(oreginal_diff) #the oreginal and predicted sample difference\n",
    "adpcm_code = np.array(adpcm_code)     #the ADPCM code the is transmited to decoder \n",
    "q_diff = np.array(q_diff)             #the quantized difference/inverse of quantization difference\n",
    "e_signal=np.array(err_signal)         #the error of the prediction (residual signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3f5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data Between 0 and 1\n",
    "y = org_samp\n",
    "ypn = pre_samp\n",
    "\n",
    "org_samp = np.array(y)\n",
    "# goal : range [0, 1]\n",
    "org_samp = (org_samp - min(org_samp)) / ( max(org_samp) - min(org_samp) )\n",
    "\n",
    "pre_samp = np.array(ypn)\n",
    "pre_samp = (pre_samp - min(pre_samp)) / ( max(pre_samp) - min(pre_samp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fdd9a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: Length is  10 :  [[[-1]\n",
      "  [-2]\n",
      "  [-1]\n",
      "  [ 2]\n",
      "  [ 5]\n",
      "  [ 4]\n",
      "  [ 0]\n",
      "  [-1]\n",
      "  [ 2]\n",
      "  [ 6]]]\n",
      "Testing Data: Length is  1 :  [[7]]\n",
      "Dimensions of X: (995530, 10, 1)\n",
      "Dimensions of Y: (995530, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===============Step 0: Data Preparation==============\n",
    "# Need the data to be in the form [sample, time steps, features (dimension of each element)]\n",
    "samples = 10 # Number of samples (in past)\n",
    "steps = 1 # Number of steps (in future)\n",
    "X = [] # X array\n",
    "Y = [] # Y array\n",
    "\n",
    "for i in range(wavdata.shape[0] - samples): \n",
    "    X.append(pre_samp[i:i+samples]) # Independent Samples\n",
    "    Y.append(org_samp[i+samples-1]) # Dependent Samples\n",
    "X = np.array(X)\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "Y = np.array(Y)\n",
    "Y = np.expand_dims(Y, axis=1)\n",
    "\n",
    "print('Training Data: Length is ',len(X[0:1][0]),': ', X[0:1])\n",
    "print('Testing Data: Length is ', len(Y[0:1]),': ', Y[0:1])\n",
    "\n",
    "print('Dimensions of X:', X.shape) \n",
    "print('Dimensions of Y:', Y.shape)\n",
    "\n",
    "# threshold = round(0.9 * X.shape[0])\n",
    "# print('Threshold is', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa99457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 3)                 54        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# =================build GRU Architectur========================\n",
    "# Let's build the GRU\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add a GRU layer with 3 units.\n",
    "model.add(layers.GRU(3,\n",
    "                     activation = \"tanh\",\n",
    "                     recurrent_activation = \"sigmoid\",\n",
    "                     input_shape=(X.shape[1], X.shape[2])))\n",
    "# Add a dropout layer (penalizing more complex models) -- prevents overfitting\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "# Add a Dense layer with 1 units (Since we are doing a regression task.\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Evaluating loss function of MSE using the adam optimizer.\n",
    "model.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "\n",
    "# Print out architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e29f15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24889/24889 [==============================] - 250s 10ms/step - loss: 0.0017 - val_loss: 6.5622e-05\n",
      "Epoch 2/50\n",
      "24889/24889 [==============================] - 236s 9ms/step - loss: 1.8731e-04 - val_loss: 5.9957e-05\n",
      "Epoch 3/50\n",
      "24889/24889 [==============================] - 229s 9ms/step - loss: 1.6595e-04 - val_loss: 5.3217e-05\n",
      "Epoch 4/50\n",
      "24889/24889 [==============================] - 256s 10ms/step - loss: 1.5322e-04 - val_loss: 5.1213e-05\n",
      "Epoch 5/50\n",
      "24889/24889 [==============================] - 236s 9ms/step - loss: 1.4170e-04 - val_loss: 3.6420e-05\n",
      "Epoch 6/50\n",
      "24889/24889 [==============================] - 251s 10ms/step - loss: 1.3389e-04 - val_loss: 3.1604e-05\n",
      "Epoch 7/50\n",
      "24889/24889 [==============================] - 247s 10ms/step - loss: 1.3100e-04 - val_loss: 3.3956e-05\n",
      "Epoch 8/50\n",
      "24889/24889 [==============================] - 248s 10ms/step - loss: 1.3196e-04 - val_loss: 2.9041e-05\n",
      "Epoch 9/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 1.3229e-04 - val_loss: 3.4985e-05\n",
      "Epoch 10/50\n",
      "24889/24889 [==============================] - 243s 10ms/step - loss: 1.2876e-04 - val_loss: 3.5263e-05\n",
      "Epoch 11/50\n",
      "24889/24889 [==============================] - 232s 9ms/step - loss: 1.2841e-04 - val_loss: 3.9974e-05\n",
      "Epoch 12/50\n",
      "24889/24889 [==============================] - 238s 10ms/step - loss: 1.3213e-04 - val_loss: 3.2990e-05\n",
      "Epoch 13/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 1.3078e-04 - val_loss: 3.8499e-05\n",
      "Epoch 14/50\n",
      "24889/24889 [==============================] - 242s 10ms/step - loss: 1.3056e-04 - val_loss: 3.5481e-05\n",
      "Epoch 15/50\n",
      "24889/24889 [==============================] - 231s 9ms/step - loss: 1.2983e-04 - val_loss: 3.1233e-05\n",
      "Epoch 16/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 1.0140e-04 - val_loss: 2.1980e-05\n",
      "Epoch 17/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.3408e-05 - val_loss: 2.0000e-05\n",
      "Epoch 18/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.5147e-05 - val_loss: 2.4050e-05\n",
      "Epoch 19/50\n",
      "24889/24889 [==============================] - 232s 9ms/step - loss: 9.4964e-05 - val_loss: 1.9111e-05\n",
      "Epoch 20/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 9.3020e-05 - val_loss: 1.8163e-05\n",
      "Epoch 21/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.3666e-05 - val_loss: 2.9611e-05\n",
      "Epoch 22/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.3693e-05 - val_loss: 1.9924e-05\n",
      "Epoch 23/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 9.3167e-05 - val_loss: 1.7116e-05\n",
      "Epoch 24/50\n",
      "24889/24889 [==============================] - 231s 9ms/step - loss: 9.3327e-05 - val_loss: 1.9808e-05\n",
      "Epoch 25/50\n",
      "24889/24889 [==============================] - 245s 10ms/step - loss: 9.3200e-05 - val_loss: 2.3847e-05\n",
      "Epoch 26/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.3550e-05 - val_loss: 1.8913e-05\n",
      "Epoch 27/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.4231e-05 - val_loss: 1.9059e-05\n",
      "Epoch 28/50\n",
      "24889/24889 [==============================] - 233s 9ms/step - loss: 9.4540e-05 - val_loss: 2.2735e-05\n",
      "Epoch 29/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.4959e-05 - val_loss: 1.7185e-05\n",
      "Epoch 30/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.2846e-05 - val_loss: 2.3801e-05\n",
      "Epoch 31/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 9.3759e-05 - val_loss: 2.4659e-05\n",
      "Epoch 32/50\n",
      "24889/24889 [==============================] - 231s 9ms/step - loss: 9.4712e-05 - val_loss: 2.7816e-05\n",
      "Epoch 33/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.3762e-05 - val_loss: 1.7605e-05\n",
      "Epoch 34/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.3488e-05 - val_loss: 2.3232e-05\n",
      "Epoch 35/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.3477e-05 - val_loss: 1.7765e-05\n",
      "Epoch 36/50\n",
      "24889/24889 [==============================] - 230s 9ms/step - loss: 9.3765e-05 - val_loss: 1.9216e-05\n",
      "Epoch 37/50\n",
      "24889/24889 [==============================] - 238s 10ms/step - loss: 9.3729e-05 - val_loss: 2.8211e-05\n",
      "Epoch 38/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 9.3733e-05 - val_loss: 2.0938e-05\n",
      "Epoch 39/50\n",
      "24889/24889 [==============================] - 239s 10ms/step - loss: 9.3478e-05 - val_loss: 2.0920e-05\n",
      "Epoch 40/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.2749e-05 - val_loss: 2.7163e-05\n",
      "Epoch 41/50\n",
      "24889/24889 [==============================] - 234s 9ms/step - loss: 9.4290e-05 - val_loss: 2.2872e-05\n",
      "Epoch 42/50\n",
      "24889/24889 [==============================] - 238s 10ms/step - loss: 9.3065e-05 - val_loss: 1.7807e-05\n",
      "Epoch 43/50\n",
      "24889/24889 [==============================] - 242s 10ms/step - loss: 9.4168e-05 - val_loss: 2.1763e-05\n",
      "Epoch 44/50\n",
      "24889/24889 [==============================] - 241s 10ms/step - loss: 9.2394e-05 - val_loss: 1.7553e-05\n",
      "Epoch 45/50\n",
      "24889/24889 [==============================] - 234s 9ms/step - loss: 9.3975e-05 - val_loss: 2.3696e-05\n",
      "Epoch 46/50\n",
      "24889/24889 [==============================] - 245s 10ms/step - loss: 9.3873e-05 - val_loss: 2.3630e-05\n",
      "Epoch 47/50\n",
      "24889/24889 [==============================] - 244s 10ms/step - loss: 9.2588e-05 - val_loss: 2.2931e-05\n",
      "Epoch 48/50\n",
      "24889/24889 [==============================] - 240s 10ms/step - loss: 9.2174e-05 - val_loss: 2.1443e-05\n",
      "Epoch 49/50\n",
      "24889/24889 [==============================] - 228s 9ms/step - loss: 9.2639e-05 - val_loss: 2.0715e-05\n",
      "Epoch 50/50\n",
      "24889/24889 [==============================] - 238s 10ms/step - loss: 9.2573e-05 - val_loss: 1.8531e-05\n"
     ]
    }
   ],
   "source": [
    "#============Training the model with the given inputs==============\n",
    "history = model.fit(X[:],\n",
    "                    Y[:],\n",
    "                    \n",
    "                    shuffle = False, # Since this is time series data\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1) # Verbose outputs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7afdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2410d9f1910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================Plotting the loss iteration===========================\n",
    "plt.plot(history.history['loss'], label = 'training loss')\n",
    "plt.plot(history.history['val_loss'], label ='validation loss')\n",
    "plt.legend()\n",
    "# Note:\n",
    "# if training loss >> validation loss -> Underfitting\n",
    "# if training loss << validation loss -> Overfitting (i.e model is smart enough to have mapped the entire dataset..)\n",
    "# Several ways to address overfitting:\n",
    "# Reduce complexity of model (hidden layers, neurons, parameters input etc)\n",
    "# Add dropout and tune rate\n",
    "# More data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the trained model\n",
    "# https://www.youtube.com/watch?v=vJWbSTJYXGM&t=236s \n",
    "model.save('G_ADPCM_GRU_speech_coding_trained_model_Adam_epoch_50_length_of_step_15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d4dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
